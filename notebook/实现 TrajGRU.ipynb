{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一步实现 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal { M } _ { c , i , j } = \\sum _ { m = 1 } ^ { H } \\sum _ { n = 1 } ^ { W } \\mathcal { I } _ { c , m , n } \\max \\left( 0,1 - \\left| i + \\mathbf { V } _ { i , j } - m \\right| \\right) \\max \\left( 0,1 - \\left| j + \\mathbf { U } _ { i , j } - n \\right| \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作者使用的是: http://beta.mxnet.io/r/api/mx.symbol.GridGenerator.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对应代码:\n",
    "\n",
    "```python\n",
    "def flow_conv(data, num_filter, flows, weight, bias, name):\n",
    "    assert isinstance(flows, list)\n",
    "    warpped_data = []\n",
    "    for i in range(len(flows)):\n",
    "        flow = flows[i]\n",
    "        grid = mx.sym.GridGenerator(data=-flow, transform_type=\"warp\")\n",
    "        ele_dat = mx.sym.BilinearSampler(data=data, grid=grid)\n",
    "        warpped_data.append(ele_dat)\n",
    "    data = mx.sym.concat(*warpped_data, dim=1)\n",
    "    ret = mx.sym.Convolution(data=data,\n",
    "                             num_filter=num_filter,\n",
    "                             kernel=(1, 1),\n",
    "                             weight=weight,\n",
    "                             bias=bias,\n",
    "                             name=name)\n",
    "    return ret\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1X1 卷积对应公式的三个邻近卷积，flows 为一个 list，每个元素对应的 shape 是 (batch, 2, h, w)，对应 $U_l$，$V_l$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先 naive 实现:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "from nowcasting.hko.dataloader import HKOIterator\n",
    "from nowcasting.config import cfg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "h, w = 5, 6\n",
    "batch_size = 1\n",
    "U, V = torch.randn(batch_size, h, w), torch.randn(batch_size, h, w)\n",
    "input = torch.randn(batch_size, channels,  h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.zeros_like(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optical flow 必须在 [-1, 1], 所以这里和 mxnet 不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(channels):\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            for m in range(h):\n",
    "                for n in range(w):\n",
    "                    t1 = 1 - torch.abs(i+V[:, i, j]-m)\n",
    "                    t2 = 1 - torch.abs(j+U[:, i, j]-n)\n",
    "                    M[:, c, i, j] += input[:, c, m, n]*torch.max(t1, torch.zeros_like(t1))*torch.max(t2, torch.zeros_like(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mxnet 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "mx_flow = torch.cat([V, U]).reshape((batch_size, 2, h, w))\n",
    "mx_flow = mx.nd.array(mx_flow.numpy())\n",
    "mx_input = mx.nd.array(input.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxnet_grid = mx.ndarray.GridGenerator(data=mx_flow, transform_type=\"warp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxnet_output = mx.ndarray.BilinearSampler(data=mx_input, grid=mxnet_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input: [B, C, H, W]\n",
    "\n",
    "flow: [B, 2, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, C, H, W = input.size()\n",
    "# mesh grid \n",
    "xx = torch.arange(0, W).view(1,-1).repeat(H,1)\n",
    "yy = torch.arange(0, H).view(-1,1).repeat(1,W)\n",
    "xx = xx.view(1,1,H,W).repeat(B,1,1,1)\n",
    "yy = yy.view(1,1,H,W).repeat(B,1,1,1)\n",
    "grid = torch.cat((xx,yy),1).float()\n",
    "vgrid = grid + torch.from_numpy(mx_flow.asnumpy())\n",
    "\n",
    "# scale grid to [-1,1] \n",
    "vgrid[:,0,:,:] = 2.0*vgrid[:,0,:,:].clone() / max(W-1,1)-1.0\n",
    "vgrid[:,1,:,:] = 2.0*vgrid[:,1,:,:].clone() / max(H-1,1)-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试一下 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(vgrid.numpy()-mxnet_grid.asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很棒很棒！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/0.3.1/nn.html#torch.nn.functional.grid_sample\n",
    "vgrid = vgrid.permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0936131e-06"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(mxnet_output.asnumpy()-torch.nn.functional.grid_sample(input, vgrid).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok，完成，参考:\n",
    "* [NVlabs/PWC-Net/blob/master/PyTorch/models/PWCNet.py#L139](https://github.com/NVlabs/PWC-Net/blob/master/PyTorch/models/PWCNet.py#L139)\n",
    "* [https://discuss.pytorch.org/t/solved-how-to-do-the-interpolating-of-optical-flow/5019/12](https://discuss.pytorch.org/t/solved-how-to-do-the-interpolating-of-optical-flow/5019/12)\n",
    "* [torch.nn.functional.grid_sample](https://pytorch.org/docs/0.3.1/nn.html#torch.nn.functional.grid_sample)\n",
    "* [incubator-mxnet/src/operator/bilinear_sampler.cc](https://github.com/apache/incubator-mxnet/blob/992c3c0dd90c0723de6934e826a49bad6569eeac/src/operator/bilinear_sampler.cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要是第一个，非常完美！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting.models.trajGRU import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1171367e-06"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = wrap(input.to(cfg.GLOBAL.DEVICE), torch.from_numpy(mx_flow.asnumpy()).to(cfg.GLOBAL.DEVICE))\n",
    "np.sum(np.abs(mxnet_output.asnumpy()-output.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting.models.trajGRU import TrajGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder 第一层的 RNN 输出是 8, 96, 96；hidden size 是 64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以输出应为 S, B, hidden_size, H, W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H, W 是输入的 feature map 的高宽."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考作者的 [traj_rnn.py](https://github.com/sxjscience/HKO-7/blob/b9235ca7edd4e5bd275f1abaf6f735f8059121be/nowcasting/operators/traj_rnn.py), 里面的 forward 函数对应 1, B, C, H, W 的输入，然后再看 [unroll](https://github.com/sxjscience/HKO-7/blob/b9235ca7edd4e5bd275f1abaf6f735f8059121be/nowcasting/operators/base_rnn.py#L20], 将 rnn 展开即可。\n",
    "\n",
    "所以 trajGRU 的输出为每一 seq 的 hidden states，而最后一个 hidden states 作为 forecaster 的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, B, C, H, W = 5, 3, 8, 96, 96\n",
    "input = torch.randn((S, B, C, H, W), dtype=torch.float).to(cfg.GLOBAL.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b_h_w 参数是 downsampling 或 upsampling 之后的 feature map 的大小，需要提前计算出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zoneout 默认为 0，其他参数参考 [encoder_forecaster.py](https://github.com/sxjscience/HKO-7/blob/b9235ca7edd4e5bd275f1abaf6f735f8059121be/nowcasting/encoder_forecaster.py#L37) 和 [trajgru_55_55_33_1_64_1_192_1_192_13_13_9_b4.yml](https://github.com/sxjscience/HKO-7/blob/b9235ca7edd4e5bd275f1abaf6f735f8059121be/experiments/hko/configurations/trajgru_55_55_33_1_64_1_192_1_192_13_13_9_b4.yml#L27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrajGRU 96 96\n"
     ]
    }
   ],
   "source": [
    "trajGRU = TrajGRU(input_channel=8, num_filter=64, b_h_w=(B, H, W), zoneout=0.0, L=13,\n",
    "                 i2h_kernel=(3, 3), i2h_stride=(1, 1), i2h_pad=(1, 1),\n",
    "                 h2h_kernel=(5, 5), h2h_dilate=(1, 1),\n",
    "                 act_type=cfg.MODEL.RNN_ACT_TYPE).to(cfg.GLOBAL.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrajGRU(\n",
       "  (i2h): Conv2d(8, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (i2f_conv1): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (h2f_conv1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (flows_conv): Conv2d(32, 26, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (ret): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, next_h = trajGRU(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 64, 96, 96])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 96, 96])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_h.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文章的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrajGRU 96 96\n",
      "TrajGRU 32 32\n",
      "TrajGRU 16 16\n",
      "TrajGRU 16 16\n",
      "TrajGRU 32 32\n",
      "TrajGRU 96 96\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from nowcasting.models.encoder import Encoder\n",
    "from nowcasting.models.model import EF\n",
    "from nowcasting.models.forecaster import Forecaster\n",
    "# build model\n",
    "encoder_params = [\n",
    "    [\n",
    "        OrderedDict({'conv1_leaky_1': [1, 8, 7, 5, 1]}),\n",
    "        OrderedDict({'conv2_leaky_1': [64, 192, 5, 3, 1]}),\n",
    "        OrderedDict({'conv3_leaky_1': [192, 192, 3, 2, 1]}),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        # ConvLSTM(8, 64, 3),\n",
    "        # ConvLSTM(192, 192, 3),\n",
    "        # ConvLSTM(192, 192, 3)\n",
    "        TrajGRU(input_channel=8, num_filter=64, b_h_w=(batch_size, 96, 96), zoneout=0.0, L=13,\n",
    "                i2h_kernel=(3, 3), i2h_stride=(1, 1), i2h_pad=(1, 1),\n",
    "                h2h_kernel=(5, 5), h2h_dilate=(1, 1),\n",
    "                act_type=cfg.MODEL.RNN_ACT_TYPE),\n",
    "\n",
    "        TrajGRU(input_channel=192, num_filter=192, b_h_w=(batch_size, 32, 32), zoneout=0.0, L=13,\n",
    "                i2h_kernel=(3, 3), i2h_stride=(1, 1), i2h_pad=(1, 1),\n",
    "                h2h_kernel=(5, 5), h2h_dilate=(1, 1),\n",
    "                act_type=cfg.MODEL.RNN_ACT_TYPE),\n",
    "        TrajGRU(input_channel=192, num_filter=192, b_h_w=(batch_size, 16, 16), zoneout=0.0, L=9,\n",
    "                i2h_kernel=(3, 3), i2h_stride=(1, 1), i2h_pad=(1, 1),\n",
    "                h2h_kernel=(3, 3), h2h_dilate=(1, 1),\n",
    "                act_type=cfg.MODEL.RNN_ACT_TYPE)\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "encoder = Encoder(encoder_params[0], encoder_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "\n",
    "forecaster_params = [\n",
    "    [\n",
    "        OrderedDict({'deconv1_leaky_1': [192, 192, 4, 2, 1]}),\n",
    "        OrderedDict({'deconv2_leaky_1': [192, 64, 5, 3, 1]}),\n",
    "        OrderedDict({\n",
    "            'deconv3_leaky_1': [64, 8, 7, 5, 1],\n",
    "            'conv3_leaky_2': [8, 8, 3, 1, 1],\n",
    "            'conv3_3': [8, 1, 1, 1, 0] # 忘了删除激活函数了，妈的\n",
    "            # 忘了卷积层，分类\n",
    "        }),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        TrajGRU(input_channel=192, num_filter=192, b_h_w=(batch_size, 16, 16), zoneout=0.0, L=13,\n",
    "                i2h_kernel=(3, 3), i2h_stride=(1, 1), i2h_pad=(1, 1),\n",
    "                h2h_kernel=(3, 3), h2h_dilate=(1, 1),\n",
    "                act_type=cfg.MODEL.RNN_ACT_TYPE),\n",
    "\n",
    "        TrajGRU(input_channel=192, num_filter=192, b_h_w=(batch_size, 32, 32), zoneout=0.0, L=13,\n",
    "                i2h_kernel=(3, 3), i2h_stride=(1, 1), i2h_pad=(1, 1),\n",
    "                h2h_kernel=(5, 5), h2h_dilate=(1, 1),\n",
    "                act_type=cfg.MODEL.RNN_ACT_TYPE),\n",
    "        TrajGRU(input_channel=64, num_filter=64, b_h_w=(batch_size, 96, 96), zoneout=0.0, L=9,\n",
    "                i2h_kernel=(3, 3), i2h_stride=(1, 1), i2h_pad=(1, 1),\n",
    "                h2h_kernel=(5, 5), h2h_dilate=(1, 1),\n",
    "                act_type=cfg.MODEL.RNN_ACT_TYPE)\n",
    "    ]\n",
    "]\n",
    "\n",
    "forecaster = Forecaster(forecaster_params[0], forecaster_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "\n",
    "encoder_forecaster = EF(encoder, forecaster).to(cfg.GLOBAL.DEVICE).to(cfg.GLOBAL.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EF(\n",
       "  (encoder): Encoder(\n",
       "    (stage1): Sequential(\n",
       "      (conv1_leaky_1): Conv2d(1, 8, kernel_size=(7, 7), stride=(5, 5), padding=(1, 1))\n",
       "      (leaky_conv1_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    )\n",
       "    (rnn1): TrajGRU(\n",
       "      (i2h): Conv2d(8, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (i2f_conv1): Conv2d(8, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (h2f_conv1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (flows_conv): Conv2d(32, 26, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (ret): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (conv2_leaky_1): Conv2d(64, 192, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
       "      (leaky_conv2_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    )\n",
       "    (rnn2): TrajGRU(\n",
       "      (i2h): Conv2d(192, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (i2f_conv1): Conv2d(192, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (h2f_conv1): Conv2d(192, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (flows_conv): Conv2d(32, 26, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (ret): Conv2d(2496, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (conv3_leaky_1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (leaky_conv3_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    )\n",
       "    (rnn3): TrajGRU(\n",
       "      (i2h): Conv2d(192, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (i2f_conv1): Conv2d(192, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (h2f_conv1): Conv2d(192, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (flows_conv): Conv2d(32, 18, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (ret): Conv2d(1728, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (forecaster): Forecaster(\n",
       "    (rnn3): TrajGRU(\n",
       "      (i2h): Conv2d(192, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (i2f_conv1): Conv2d(192, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (h2f_conv1): Conv2d(192, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (flows_conv): Conv2d(32, 26, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (ret): Conv2d(2496, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (deconv1_leaky_1): ConvTranspose2d(192, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (leaky_deconv1_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    )\n",
       "    (rnn2): TrajGRU(\n",
       "      (i2h): Conv2d(192, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (i2f_conv1): Conv2d(192, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (h2f_conv1): Conv2d(192, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (flows_conv): Conv2d(32, 26, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (ret): Conv2d(2496, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (deconv2_leaky_1): ConvTranspose2d(192, 64, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
       "      (leaky_deconv2_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    )\n",
       "    (rnn1): TrajGRU(\n",
       "      (i2h): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (i2f_conv1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (h2f_conv1): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (flows_conv): Conv2d(32, 18, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (ret): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (deconv3_leaky_1): ConvTranspose2d(64, 8, kernel_size=(7, 7), stride=(5, 5), padding=(1, 1))\n",
       "      (leaky_deconv3_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "      (conv3_leaky_2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (leaky_conv3_leaky_2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "      (conv3_3): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, B, C, H, W = 5, 2, 1, 480, 480\n",
    "input = torch.randn((S, B, C, H, W), dtype=torch.float).to(cfg.GLOBAL.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = encoder_forecaster(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2, 1, 480, 480])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
