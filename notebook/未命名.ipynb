{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import torch\n",
    "from nowcasting.hko.dataloader import HKOIterator\n",
    "from nowcasting.config import cfg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_LEN = cfg.HKO.BENCHMARK.IN_LEN\n",
    "OUT_LEN = cfg.HKO.BENCHMARK.OUT_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hko_iter = HKOIterator(pd_path=cfg.HKO_PD.RAINY_TRAIN,\n",
    "                                 sample_mode=\"random\",\n",
    "                                 seq_len=IN_LEN+OUT_LEN)\n",
    "\n",
    "valid_hko_iter = HKOIterator(pd_path=cfg.HKO_PD.RAINY_VALID,\n",
    "                                 sample_mode=\"sequent\",\n",
    "                                 seq_len=IN_LEN+OUT_LEN,\n",
    "                                 stride=cfg.HKO.BENCHMARK.STRIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 2\n",
    "test_batch_size = 2\n",
    "max_iterations = 2000\n",
    "test_and_save_checkpoint_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting.models.forecaster import Forecaster\n",
    "from nowcasting.models.encoder import Encoder\n",
    "from nowcasting.models.convLSTM import ConvLSTM\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "encoder_params = [\n",
    "    [\n",
    "        OrderedDict({'conv1_leaky_1': [1, 8, 7, 5, 1]}),\n",
    "        OrderedDict({'conv2_leaky_1': [64, 192, 5, 3, 1]}),\n",
    "        OrderedDict({'conv3_leaky_1': [192, 192, 3, 2, 1]}),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        ConvLSTM(8, 64, 3),\n",
    "        ConvLSTM(192, 192, 3),\n",
    "        ConvLSTM(192, 192, 3)\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (stage1): Sequential(\n",
       "    (conv1_leaky_1): Conv2d(1, 8, kernel_size=(7, 7), stride=(5, 5), padding=(1, 1))\n",
       "    (leaky_conv1_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (rnn1): ConvLSTM(\n",
       "    (_cell): ConvLSTMCell(\n",
       "      (_conv): Conv2d(72, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (stage2): Sequential(\n",
       "    (conv2_leaky_1): Conv2d(64, 192, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
       "    (leaky_conv2_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (rnn2): ConvLSTM(\n",
       "    (_cell): ConvLSTMCell(\n",
       "      (_conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (conv3_leaky_1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (leaky_conv3_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (rnn3): ConvLSTM(\n",
       "    (_cell): ConvLSTMCell(\n",
       "      (_conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(encoder_params[0], encoder_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster_params = [\n",
    "    [\n",
    "        OrderedDict({'deconv1_leaky_1': [192, 192, 4, 2, 1]}),\n",
    "        OrderedDict({'deconv2_leaky_1': [192, 64, 5, 3, 1]}),\n",
    "        OrderedDict({\n",
    "            'deconv3_leaky_1': [64, 8, 7, 5, 1],\n",
    "            'conv3_leaky_2': [8, 8, 3, 1, 1],\n",
    "            'conv3_3': [8, 1, 1, 1, 0] # 忘了删除激活函数了，妈的\n",
    "            # 忘了卷积层，分类\n",
    "        }),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        ConvLSTM(192, 192, 3),\n",
    "        ConvLSTM(192, 192, 3),\n",
    "        ConvLSTM(64, 64, 3)\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Forecaster(\n",
       "  (rnn3): ConvLSTM(\n",
       "    (_cell): ConvLSTMCell(\n",
       "      (_conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (deconv1_leaky_1): ConvTranspose2d(192, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (leaky_deconv1_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (rnn2): ConvLSTM(\n",
       "    (_cell): ConvLSTMCell(\n",
       "      (_conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (stage2): Sequential(\n",
       "    (deconv2_leaky_1): ConvTranspose2d(192, 64, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
       "    (leaky_deconv2_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (rnn1): ConvLSTM(\n",
       "    (_cell): ConvLSTMCell(\n",
       "      (_conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (stage1): Sequential(\n",
       "    (deconv3_leaky_1): ConvTranspose2d(64, 8, kernel_size=(7, 7), stride=(5, 5), padding=(1, 1))\n",
       "    (leaky_deconv3_leaky_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (conv3_leaky_2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (leaky_conv3_leaky_2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (conv3_3): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = Forecaster(forecaster_params[0], forecaster_params[1]).to(cfg.GLOBAL.DEVICE)\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting.models.model import EF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_forecaster = EF(encoder, forecaster).to(cfg.GLOBAL.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EF(\n",
       "  (encoder): Encoder(\n",
       "    (stage1): Sequential(\n",
       "      (conv1_1): Conv2d(1, 8, kernel_size=(7, 7), stride=(5, 5), padding=(1, 1))\n",
       "      (relu_conv1_1): ReLU(inplace)\n",
       "    )\n",
       "    (rnn1): ConvLSTM(\n",
       "      (_cell): ConvLSTMCell(\n",
       "        (_conv): Conv2d(72, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (conv2_1): Conv2d(64, 192, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
       "      (relu_conv2_1): ReLU(inplace)\n",
       "    )\n",
       "    (rnn2): ConvLSTM(\n",
       "      (_cell): ConvLSTMCell(\n",
       "        (_conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (conv3_1): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (relu_conv3_1): ReLU(inplace)\n",
       "    )\n",
       "    (rnn3): ConvLSTM(\n",
       "      (_cell): ConvLSTMCell(\n",
       "        (_conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (forecaster): Forecaster(\n",
       "    (rnn3): ConvLSTM(\n",
       "      (_cell): ConvLSTMCell(\n",
       "        (_conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (deconv1_1): ConvTranspose2d(192, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (relu_deconv1_1): ReLU(inplace)\n",
       "    )\n",
       "    (rnn2): ConvLSTM(\n",
       "      (_cell): ConvLSTMCell(\n",
       "        (_conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (deconv2_1): ConvTranspose2d(192, 64, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
       "      (relu_deconv2_1): ReLU(inplace)\n",
       "    )\n",
       "    (rnn1): ConvLSTM(\n",
       "      (_cell): ConvLSTMCell(\n",
       "        (_conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (deconv3_1): ConvTranspose2d(64, 8, kernel_size=(7, 7), stride=(5, 5), padding=(1, 1))\n",
       "      (relu_deconv3_1): ReLU(inplace)\n",
       "      (deconv4_2): ConvTranspose2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu_deconv4_2): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "optimizer = torch.optim.Adam(encoder_forecaster.parameters(), lr=LR)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "test_iteration_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting.hko.evaluation import HKOEvaluation\n",
    "evaluater = HKOEvaluation(seq_len=OUT_LEN, use_central=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7263621687889099\n",
      "0.821571409702301\n",
      "0.7881657481193542\n",
      "0.7651374936103821\n",
      "0.6349201202392578\n",
      "0.7382422089576721\n",
      "0.6729480028152466\n",
      "0.6955388188362122\n",
      "0.6149008870124817\n",
      "0.6411648988723755\n",
      "0.6127393841743469\n",
      "0.5829384326934814\n",
      "0.5575474500656128\n",
      "0.5201427936553955\n",
      "0.5508731007575989\n",
      "0.46293848752975464\n",
      "0.49638161063194275\n",
      "0.4191792607307434\n",
      "0.46300461888313293\n",
      "0.4250716269016266\n",
      "0.4182124137878418\n",
      "0.4105169475078583\n",
      "0.4006730914115906\n",
      "0.3718911111354828\n",
      "0.3777596056461334\n",
      "0.35242393612861633\n",
      "0.33277982473373413\n",
      "0.33807477355003357\n",
      "0.29463711380958557\n",
      "0.3016614615917206\n",
      "0.2887493669986725\n",
      "0.2396143078804016\n",
      "0.24983742833137512\n",
      "0.22717474400997162\n",
      "0.22936341166496277\n",
      "0.22979500889778137\n",
      "0.22087819874286652\n",
      "0.20947781205177307\n",
      "0.190176859498024\n",
      "0.17819832265377045\n",
      "0.17923912405967712\n",
      "0.1791492998600006\n",
      "0.1562056541442871\n",
      "0.15579786896705627\n",
      "0.1500856727361679\n",
      "0.1437840610742569\n",
      "0.1425778865814209\n",
      "0.13841843605041504\n",
      "0.1223856583237648\n",
      "0.12771092355251312\n",
      "0.12090755254030228\n",
      "0.12183642387390137\n",
      "0.11154396086931229\n",
      "0.10770289599895477\n",
      "0.11906484514474869\n",
      "0.10856621712446213\n",
      "0.09914951026439667\n",
      "0.09421616792678833\n",
      "0.0940404087305069\n",
      "0.08869962394237518\n",
      "0.08702106028795242\n",
      "0.08616649359464645\n",
      "0.08451812714338303\n",
      "0.08786047995090485\n",
      "0.07983704656362534\n",
      "0.08005497604608536\n",
      "0.06837479025125504\n",
      "0.06996599584817886\n",
      "0.06537912786006927\n",
      "0.08174575865268707\n",
      "0.06418418139219284\n",
      "0.0945933535695076\n",
      "0.06167825683951378\n",
      "0.06898683309555054\n",
      "0.08061064034700394\n",
      "0.08112236857414246\n",
      "0.07002255320549011\n",
      "0.05539746582508087\n",
      "0.058775343000888824\n",
      "0.05422591045498848\n",
      "0.050001002848148346\n",
      "0.05240202322602272\n",
      "0.05317655950784683\n",
      "0.06022441387176514\n",
      "0.04484668746590614\n",
      "0.06054810434579849\n",
      "0.044539425522089005\n",
      "0.04106278717517853\n",
      "0.05108772963285446\n",
      "0.04120596870779991\n",
      "0.04294826462864876\n",
      "0.039711229503154755\n",
      "0.03752676770091057\n",
      "0.06442832946777344\n",
      "0.0419299453496933\n",
      "0.05426637828350067\n",
      "0.03830184042453766\n",
      "0.04154876992106438\n",
      "0.0483536459505558\n",
      "0.04166368022561073\n",
      "0.03620900586247444\n",
      "0.03716067224740982\n",
      "0.03380105644464493\n",
      "0.07105741649866104\n",
      "0.03841027989983559\n",
      "0.030504414811730385\n",
      "0.03590628132224083\n",
      "0.03852758929133415\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ceaf4afa947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#     train_loss += loss.item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mevaluater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = 0.0\n",
    "test_loss = 0.0\n",
    "\n",
    "for itera in range(max_iterations):\n",
    "    if itera%test_iteration_interval==0:\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "        evaluater.clear_all()\n",
    "        with torch.no_grad():\n",
    "            pass\n",
    "    train_batch, train_mask, sample_datetimes, _ = \\\n",
    "                train_hko_iter.sample(batch_size=train_batch_size)\n",
    "    train_batch = torch.from_numpy(train_batch.astype(np.float32)).to(cfg.GLOBAL.DEVICE)/255.0\n",
    "    train_data = train_batch[:IN_LEN, ...]\n",
    "    train_label = train_batch[IN_LEN:IN_LEN+OUT_LEN, ...]\n",
    "    mask = torch.from_numpy(train_mask[IN_LEN:IN_LEN+OUT_LEN, ...].astype(int)).to(cfg.GLOBAL.DEVICE)\n",
    "    \n",
    "    encoder_forecaster.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = encoder_forecaster(train_data)\n",
    "    loss = criterion(output, train_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     train_loss += loss.item()\n",
    "    train_loss = loss.item()\n",
    "    evaluater.update(train_label.cpu().numpy(), output.detach().cpu().numpy(), mask.cpu().numpy())\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
